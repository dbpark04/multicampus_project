# 전처리 결과 파일 구조

전처리 파이프라인 실행 후 생성되는 Parquet 파일들의 구조를 설명합니다.

---

## 생성되는 파일

1. **integrated_products_final.parquet** - 모든 상품 정보 통합
2. **category_summary.parquet** - 카테고리별 통계 요약
3. **detailed*stats/detailed_stats_category*{카테고리}.parquet** - 카테고리별 감성 키워드 통계
4. **partitioned*reviews/partitioned_reviews_category*{카테고리}.parquet** - 카테고리별 리뷰 데이터

---

## 1. integrated_products_final.parquet

**위치**: `data/processed_data/integrated_products_final.parquet`

**설명**: 모든 카테고리의 상품 정보를 통합한 메인 Parquet 파일

### 컬럼 구조

```python
[
    'product_id',                    # str: "선스틱_123"
    'product_name',                  # str: 전체 상품명
    'brand',                         # str: 표준화된 브랜드명
    'category',                      # str: 카테고리명 (예: "선스틱")
    'category_path',                 # str: 전체 카테고리 경로
    'path',                          # str: 카테고리 경로의 마지막 항목
    'price',                         # str: 가격
    'delivery_type',                 # str: 배송 유형
    'product_url',                   # str: 상품 URL
    'skin_type',                     # str: 피부 타입 분류
    'top_keywords',                  # list[str]: 긍정 키워드 상위 5개
    'sentiment_analysis',            # dict: 감성 분석 결과
    'product_vector',                # list[float]: Word2Vec 상품 벡터
    'representative_review_id',      # int: 대표 리뷰 ID
    'representative_similarity',     # float: 대표 리뷰 유사도
    'avg_rating_with_text',          # float: 텍스트 있는 리뷰 평균 평점
    'avg_rating_without_text',       # float: 텍스트 없는 리뷰 평균 평점
    'text_review_ratio',             # float: 텍스트 리뷰 비율 (%)
    'total_reviews',                 # int: 총 리뷰 수
    'rating_1',                      # int: 1점 리뷰 수
    'rating_2',                      # int: 2점 리뷰 수
    'rating_3',                      # int: 3점 리뷰 수
    'rating_4',                      # int: 4점 리뷰 수
    'rating_5'                       # int: 5점 리뷰 수
]
```

### 사용 예시

```python
import pandas as pd

df = pd.read_parquet('data/processed_data/integrated_products_final.parquet')

# 특정 카테고리 필터링
sunstick = df[df['category'] == '선스틱']

# 건성 피부 추천 상품
dry_skin = df[(df['skin_type'] == '건성') & (df['avg_rating_with_text'] >= 4.5)]
```

---

## 2. category_summary.parquet

**위치**: `data/processed_data/category_summary.parquet`

**설명**: 카테고리별 통합 통계 요약

### 컬럼 구조

```python
[
    'category',         # str: 카테고리명
    'total_reviews',    # int: 전체 리뷰 수
    'text_reviews',     # int: 텍스트 있는 리뷰 수
    'no_text_reviews',  # int: 텍스트 없는 리뷰 수
    'rating_1',         # int: 1점 리뷰 수
    'rating_2',         # int: 2점 리뷰 수
    'rating_3',         # int: 3점 리뷰 수
    'rating_4',         # int: 4점 리뷰 수
    'rating_5'          # int: 5점 리뷰 수
]
```

### 사용 예시

```python
import pandas as pd

df = pd.read_parquet('data/processed_data/category_summary.parquet')

# 카테고리별 리뷰 수 확인
print(df[['category', 'total_reviews', 'text_reviews']])

# 텍스트 리뷰 비율이 높은 카테고리
df['text_ratio'] = df['text_reviews'] / df['total_reviews'] * 100
high_text = df.nlargest(5, 'text_ratio')
```

---

## 3. detailed*stats_category*{카테고리}.parquet

**위치**: `data/processed_data/detailed_stats/detailed_stats_category_{카테고리}.parquet`

**설명**: 카테고리별 감성 키워드 통계

### 컬럼 구조

```python
[
    'product_id',      # str: 상품 ID
    'word',            # str: 키워드
    'diff',            # float: TF-IDF 차이값
    'pos',             # float: 긍정 리뷰 비율
    'neg',             # float: 부정 리뷰 비율
    'pos_n',           # int: 긍정 리뷰 출현 횟수
    'neg_n',           # int: 부정 리뷰 출현 횟수
    'support',         # int: 총 출현 횟수
    'balanced_ratio',  # float: 균형 비율
    'score',           # float: 중요도 점수
    'sentiment_type'   # str: "positive" 또는 "negative"
]
```

### 파일 예시

- `detailed_stats_category_선스틱.parquet`
- `detailed_stats_category_선스프레이.parquet`
- `detailed_stats_category_선케어_선크림_선로션.parquet`
- `detailed_stats_category_선쿠션_선팩트.parquet`

### 사용 예시

```python
import pandas as pd

df = pd.read_parquet('data/processed_data/detailed_stats/detailed_stats_category_선케어_선크림_선로션.parquet')

# 긍정 키워드 상위 10개
top_positive = df[df['sentiment_type'] == 'positive'].nlargest(10, 'score')

# 부정 키워드 상위 10개
top_negative = df[df['sentiment_type'] == 'negative'].nlargest(10, 'score')
```

---

## 4. partitioned*reviews_category*{카테고리}.parquet

**위치**: `data/processed_data/partitioned_reviews/partitioned_reviews_category_{카테고리}.parquet`

**설명**: 카테고리별 리뷰 데이터

### 컬럼 구조

```python
[
    'product_id',      # str: 상품 ID
    'id',              # int: 리뷰 ID
    'full_text',       # str: 리뷰 전문 (title + content)
    'title',           # str: 리뷰 제목
    'content',         # str: 리뷰 본문
    'has_text',        # bool: 텍스트 여부
    'score',           # int: 별점 (1~5)
    'label',           # float: 감성 라벨 (1=긍정, 0=부정, None=중립)
    'tokens',          # list[str]: 토큰화된 단어 배열
    'char_length',     # int: 리뷰 글자 수
    'token_count',     # int: 토큰 개수
    'date',            # str: 리뷰 작성일 (YYYY-MM-DD)
    'collected_at',    # str: 수집 시간
    'nickname',        # str: 작성자 닉네임
    'has_image',       # bool/None: 이미지 첨부 여부
    'helpful_count',   # float: 도움됨 수
    'sentiment_score', # None or float: 감성 점수 (0~1, model/predict_sentiment_scores.py 실행 시 추가)
    'word2vec'         # list[float]: Word2Vec 벡터 (100차원)
]
```

> **Note**: `sentiment_score`는 전처리 직후에는 `None`이며, `src/model/predict_sentiment_scores.py`를 실행하면 0.0~1.0 사이의 긍정 확률값으로 채워집니다.

### 파일 예시

- `partitioned_reviews_category_선스틱.parquet`
- `partitioned_reviews_category_선스프레이.parquet`
- `partitioned_reviews_category_선케어_선크림_선로션.parquet`
- `partitioned_reviews_category_선쿠션_선팩트.parquet`

### 사용 예시

```python
import pandas as pd

df = pd.read_parquet('data/processed_data/partitioned_reviews/partitioned_reviews_category_선케어_선크림_선로션.parquet')

# 텍스트 리뷰만 필터링
text_reviews = df[df['has_text'] == True]

# 특정 상품의 리뷰
product_reviews = df[df['product_id'] == '선케어_선크림_선로션_123']

# 긍정 리뷰만 추출
positive = df[df['label'] == 1]
```

---

## 파일 간 관계도

```
전처리 파이프라인 실행 (main.py)
        ↓
┌────────────────────────────────────────────┐
│ Phase 1: 전처리 + 토큰화                  │
│  - 포맷 정리                               │
│  - 브랜드 표준화                           │
│  - 결측치 제거                             │
│  - 피부타입 분류                           │
│  - 토큰화                                  │
└────────────────────────────────────────────┘
        ↓
┌────────────────────────────────────────────┐
│ Phase 2: Word2Vec 모델 학습                │
└────────────────────────────────────────────┘
        ↓
┌────────────────────────────────────────────┐
│ Phase 3: 벡터화 + 감성 분석                │
│  - 리뷰 벡터화                             │
│  - 대표 리뷰 선정                          │
│  - 감성 키워드 분석                        │
└────────────────────────────────────────────┘
        ↓
┌────────────────────────────────────────────┐
│ 4가지 Parquet 파일 생성                    │
│ (sentiment_score는 None 상태)              │
├────────────────────────────────────────────┤
│ 1. integrated_products_final.parquet       │
│    - 상품 정보 + 통계 + 벡터               │
│                                            │
│ 2. category_summary.parquet                │
│    - 카테고리별 통계 요약                  │
│                                            │
│ 3. detailed_stats_category_*.parquet       │
│    - 카테고리별 감성 키워드                │
│                                            │
│ 4. partitioned_reviews_category_*.parquet  │
│    - 카테고리별 리뷰 데이터                │
└────────────────────────────────────────────┘
        ↓
┌────────────────────────────────────────────┐
│ [선택] 모델 학습 및 sentiment_score 추가  │
│ (src/model/ 폴더)                          │
├────────────────────────────────────────────┤
│ 1. train_sentiment_model.py                │
│    → models/sentiment_model.joblib 생성    │
│                                            │
│ 2. predict_sentiment_scores.py             │
│    → partitioned_reviews에 sentiment_score │
│      추가 (0~1 긍정 확률)                  │
└────────────────────────────────────────────┘
```

---

## 분석 목적별 추천 파일

| 목적                 | 추천 파일                                                |
| -------------------- | -------------------------------------------------------- |
| 상품 추천 시스템     | integrated_products_final.parquet                        |
| 카테고리 통계 분석   | category_summary.parquet                                 |
| 리뷰 검색/분석       | partitioned*reviews_category*\*.parquet                  |
| 감성 키워드 분석     | detailed*stats_category*\*.parquet                       |
| 텍스트 리뷰 분석     | partitioned_reviews (has_text=True)                      |
| 평점 분석            | integrated_products_final (rating_1~5)                   |
| 텍스트 유무별 평점   | integrated_products_final (avg_rating_with/without_text) |
| 카테고리별 리뷰 분포 | category_summary + partitioned_reviews                   |

---

## 데이터 조합 예시

```python
import pandas as pd
from pathlib import Path

# 1. 상품 정보 로드
products = pd.read_parquet('data/processed_data/integrated_products_final.parquet')

# 2. 카테고리 통계 로드
category_summary = pd.read_parquet('data/processed_data/category_summary.parquet')

# 3. 특정 카테고리의 리뷰 로드
reviews = pd.read_parquet('data/processed_data/partitioned_reviews/partitioned_reviews_category_선케어_선크림_선로션.parquet')

# 4. 감성 키워드 로드
stats = pd.read_parquet('data/processed_data/detailed_stats/detailed_stats_category_선케어_선크림_선로션.parquet')

# 5. 상품-리뷰 조인
merged = products.merge(reviews, on='product_id', how='inner')

# 6. 텍스트 리뷰만 분석
text_only = reviews[reviews['has_text'] == True]

# 7. 모든 카테고리 리뷰 통합 로드
reviews_dir = Path('data/processed_data/partitioned_reviews')
all_reviews = []
for file in reviews_dir.glob('partitioned_reviews_category_*.parquet'):
    df = pd.read_parquet(file)
    all_reviews.append(df)
all_reviews_df = pd.concat(all_reviews, ignore_index=True)

print(f"총 상품 수: {len(products)}")
print(f"총 카테고리 수: {len(category_summary)}")
print(f"총 리뷰 수: {len(all_reviews_df)}")
```
